{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68e9b36f",
   "metadata": {},
   "source": [
    "# Loading exploratory data analysis packages\n",
    "Exploratory data analysis(EDA) packages are used for data analysis and data manipulation. We shall use pandas to read our dataset and numpy to perform mathematical computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "86c07abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4adcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We use pandas to load our dataset.\n",
    "dataset_Textfilter= pd.read_csv('dataset_textfilter.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a59081a",
   "metadata": {},
   "source": [
    "# Checking data structure\n",
    "We check the structure to be able to see the available columns in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "78430c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Area (Feets)</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Bath Room</th>\n",
       "      <th>Living Rooms</th>\n",
       "      <th>Kitchen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Area is 1000 square feet. I want 1 bedroom. 1 ...</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It is 1500 square feet. I want to. Two bedroom...</td>\n",
       "      <td>1500</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Area is 1300 square feet. I want to. three bed...</td>\n",
       "      <td>1300</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Area is 900 square feet. two Bedroom. Two wash...</td>\n",
       "      <td>900</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Area is 1000 square feet. I want three bedroom...</td>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Input  Area (Feets)  Rooms  \\\n",
       "0  Area is 1000 square feet. I want 1 bedroom. 1 ...          1000      1   \n",
       "1  It is 1500 square feet. I want to. Two bedroom...          1500      2   \n",
       "2  Area is 1300 square feet. I want to. three bed...          1300      3   \n",
       "3  Area is 900 square feet. two Bedroom. Two wash...           900      2   \n",
       "4  Area is 1000 square feet. I want three bedroom...          1000      3   \n",
       "\n",
       "   Bath Room  Living Rooms  Kitchen  \n",
       "0          1             1        1  \n",
       "1          1             1        1  \n",
       "2          1             1        1  \n",
       "3          2             1        1  \n",
       "4          3             1        1  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_Textfilter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581f7493",
   "metadata": {},
   "source": [
    "# Datatype of our labels\n",
    "We check the data type of our labels as they need to have a uniform data type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "2f7af91c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Input           object\n",
       "Area (Feets)     int64\n",
       "Rooms            int64\n",
       "Bath Room        int64\n",
       "Living Rooms     int64\n",
       "Kitchen          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_Textfilter.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c05b95",
   "metadata": {},
   "source": [
    "# Loading machine learning packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "deddba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.metrics import accuracy_score,hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f81b9",
   "metadata": {},
   "source": [
    "# Importing problem transformation packages\n",
    "We will use the problem transformation packages to handle the three techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788a9a04",
   "metadata": {},
   "source": [
    "# import sys\n",
    "\n",
    "! {sys.executable} -m pip install scikit-multilearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2606d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skmultilearn.problem_transform import BinaryRelevance\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "from skmultilearn.problem_transform import LabelPowerset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ce54e2",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "Text preprocessing involves removing stop words and removal of noisy data. Stop words are a list of all words that are common in a given language.\n",
    "\n",
    "Stop words are removed since they do not have a high classification power during predictive analysis. They tend to bring bias when building the classifier.\n",
    "\n",
    "We remove noisy data that affect our model during training and bring errors in our model.\n",
    "\n",
    "To perform text preprocessing, we need to install the neattext package. Neattext is a Python package used for textual data cleaning and text preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d8967",
   "metadata": {},
   "source": [
    "# import sys\n",
    "! {sys.executable} -m pip install neattext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "483f616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import neattext as nt\n",
    "import neattext.functions as nfx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199a0ad",
   "metadata": {},
   "source": [
    "# Exploring the dataset for noise\n",
    "Noise is the unwanted character in our dataset that may affect our model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "9a049900",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'text_noise': 10.0, 'text_length': 90, 'noise...\n",
       "1     {'text_noise': 14.583333333333334, 'text_lengt...\n",
       "2     {'text_noise': 13.0, 'text_length': 100, 'nois...\n",
       "3     {'text_noise': 10.588235294117647, 'text_lengt...\n",
       "4     {'text_noise': 12.244897959183673, 'text_lengt...\n",
       "5     {'text_noise': 14.583333333333334, 'text_lengt...\n",
       "6     {'text_noise': 10.638297872340425, 'text_lengt...\n",
       "7     {'text_noise': 10.588235294117647, 'text_lengt...\n",
       "8     {'text_noise': 10.588235294117647, 'text_lengt...\n",
       "9     {'text_noise': 12.5, 'text_length': 96, 'noise...\n",
       "10    {'text_noise': 12.76595744680851, 'text_length...\n",
       "11    {'text_noise': 12.76595744680851, 'text_length...\n",
       "12    {'text_noise': 13.043478260869565, 'text_lengt...\n",
       "13    {'text_noise': 10.0, 'text_length': 90, 'noise...\n",
       "14    {'text_noise': 14.14141414141414, 'text_length...\n",
       "15    {'text_noise': 12.76595744680851, 'text_length...\n",
       "16    {'text_noise': 10.227272727272728, 'text_lengt...\n",
       "17    {'text_noise': 14.583333333333334, 'text_lengt...\n",
       "18    {'text_noise': 12.903225806451612, 'text_lengt...\n",
       "19    {'text_noise': 10.588235294117647, 'text_lengt...\n",
       "20    {'text_noise': 10.75268817204301, 'text_length...\n",
       "21    {'text_noise': 14.285714285714285, 'text_lengt...\n",
       "22    {'text_noise': 12.244897959183673, 'text_lengt...\n",
       "23    {'text_noise': 10.227272727272728, 'text_lengt...\n",
       "24    {'text_noise': 14.583333333333334, 'text_lengt...\n",
       "25    {'text_noise': 10.112359550561797, 'text_lengt...\n",
       "26    {'text_noise': 12.903225806451612, 'text_lengt...\n",
       "27    {'text_noise': 10.465116279069768, 'text_lengt...\n",
       "28    {'text_noise': 12.5, 'text_length': 96, 'noise...\n",
       "29    {'text_noise': 14.583333333333334, 'text_lengt...\n",
       "30    {'text_noise': 10.0, 'text_length': 90, 'noise...\n",
       "31    {'text_noise': 10.344827586206897, 'text_lengt...\n",
       "32    {'text_noise': 14.14141414141414, 'text_length...\n",
       "33    {'text_noise': 12.903225806451612, 'text_lengt...\n",
       "34    {'text_noise': 10.0, 'text_length': 90, 'noise...\n",
       "35    {'text_noise': 12.76595744680851, 'text_length...\n",
       "36    {'text_noise': 12.76595744680851, 'text_length...\n",
       "37    {'text_noise': 14.285714285714285, 'text_lengt...\n",
       "38    {'text_noise': 10.344827586206897, 'text_lengt...\n",
       "39    {'text_noise': 14.736842105263156, 'text_lengt...\n",
       "Name: Input, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_Textfilter['Input'].apply(lambda x:nt.TextFrame(x).noise_scan())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccc53ee",
   "metadata": {},
   "source": [
    "# We explore the noise data from the Input column. It shows all the rows containing noise words from the first row 0 to 39 and the noise data in these rows. The first value is 10, and the last is 14. We can now extract the stop words from these noisy data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efb82a0",
   "metadata": {},
   "source": [
    "# Extracting stop words\n",
    "We use the TextExtractor() and extract_stopwords() methods to extract all the stop words available in our title column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "549dd38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_Textfilter['Input'].apply(lambda x:nt.TextExtractor(x).extract_stopwords())\n",
    "#The output of the stop words is shown:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7fb20c",
   "metadata": {},
   "source": [
    "# Removing stop words\n",
    "We remove stop words using the nfx.remove_stopwords function as shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1051a2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_Textfilter['Input'].apply(nfx.remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896f8453",
   "metadata": {},
   "source": [
    "# Saving dataset in a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd9b6792",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = dataset_Textfilter['Input']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e8ede2",
   "metadata": {},
   "source": [
    "# using the TfidfVectorizer() package to conduct feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ec774ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8347292f",
   "metadata": {},
   "source": [
    "# Extracting features\n",
    "The features will be numeric values as stated above. The features will be used as input for the model during training and predictive analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "c1472ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfeatures = tfidf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cb207c",
   "metadata": {},
   "source": [
    "# showing array of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d2525a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5144811 , 0.        , 0.        , ..., 0.20681713, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.1722858 , 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.459373  , ..., 0.17227965, 0.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.        , 0.        , 0.        , ..., 0.16863856, 0.        ,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.        , 0.35790026,\n",
       "        0.        ],\n",
       "       [0.        , 0.        , 0.        , ..., 0.16997643, 0.        ,\n",
       "        0.        ]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xfeatures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
