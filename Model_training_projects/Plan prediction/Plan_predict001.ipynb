{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a2756a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import nltk\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, GlobalMaxPooling1D,Flatten\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.models import Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7d4d6cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the dataset\n",
    "content = open('dataset_plans001.json' , encoding='utf-8')\n",
    "data1 = json.load(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c71ae773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting all the data to lists\n",
    "tags = []\n",
    "inputs = []\n",
    "responses = {}\n",
    "for intent in data1['intents']:\n",
    "    responses[intent['tag']]=intent['responses']\n",
    "    for lines in intent['input']:\n",
    "        inputs.append(lines)\n",
    "        tags.append(intent['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "220027d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting to dataframe\n",
    "data = pd.DataFrame({\"input\":inputs,\"tag\":tags})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "537cc89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input tag\n",
       "0    11   1\n",
       "1    12   2\n",
       "2    21   3\n",
       "3    22   4\n",
       "4    31   5\n",
       "5    32   6"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing the data\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a02f0cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input tag\n",
       "0    11   1\n",
       "1    12   2\n",
       "2    21   3\n",
       "3    22   4\n",
       "4    31   5\n",
       "5    32   6"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#removing punctuations\n",
    "import string\n",
    "data['input'] = data['input'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
    "data['input'] = data['input'].apply(lambda wrd: ''.join(wrd))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "52f15bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the data\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=2000)\n",
    "tokenizer.fit_on_texts(data['input'])\n",
    "train = tokenizer.texts_to_sequences(data['input'])\n",
    "#apply padding\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "x_train = pad_sequences(train)\n",
    "\n",
    "#encoding the outputs\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(data['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dd9ec573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1]\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3d0825d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words :  6\n",
      "output length:  6\n"
     ]
    }
   ],
   "source": [
    "#define vocabulary\n",
    "vocabulary = len(tokenizer.word_index)\n",
    "print(\"number of unique words : \",vocabulary)\n",
    "output_length = le.classes_.shape[0]\n",
    "print(\"output length: \",output_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2d5188ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    #creating the model\n",
    "    i = Input(shape=(input_shape,))\n",
    "    x = Embedding(vocabulary+1,10)(i)\n",
    "    x = LSTM(10,return_sequences=True)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(output_length,activation=\"softmax\")(x)\n",
    "    model = Model(i,x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "406833dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "89785b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compiling the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "67ee7802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1/1 [==============================] - 3s 3s/step - loss: 1.7885 - accuracy: 0.5000\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7880 - accuracy: 0.3333\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7875 - accuracy: 0.3333\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7870 - accuracy: 0.5000\n",
      "Epoch 5/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7864 - accuracy: 0.5000\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7859 - accuracy: 0.6667\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7854 - accuracy: 0.6667\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 1.7848 - accuracy: 0.6667\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7843 - accuracy: 0.6667\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7838 - accuracy: 0.6667\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7832 - accuracy: 0.6667\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 1.7827 - accuracy: 0.6667\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7821 - accuracy: 0.6667\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7816 - accuracy: 0.6667\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.7810 - accuracy: 0.6667\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.7804 - accuracy: 0.6667\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7799 - accuracy: 0.6667\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.7793 - accuracy: 0.6667\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7787 - accuracy: 0.6667\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7781 - accuracy: 0.6667\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7774 - accuracy: 0.6667\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7768 - accuracy: 0.6667\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7761 - accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7755 - accuracy: 0.6667\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7748 - accuracy: 0.6667\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7741 - accuracy: 0.6667\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7734 - accuracy: 0.6667\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7727 - accuracy: 0.6667\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7720 - accuracy: 0.6667\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7712 - accuracy: 0.6667\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7704 - accuracy: 0.6667\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7696 - accuracy: 0.6667\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7688 - accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7680 - accuracy: 0.6667\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7672 - accuracy: 0.6667\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7663 - accuracy: 0.6667\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7654 - accuracy: 0.6667\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7645 - accuracy: 0.6667\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7636 - accuracy: 0.6667\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7626 - accuracy: 0.6667\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7616 - accuracy: 0.6667\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7606 - accuracy: 0.6667\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7596 - accuracy: 0.6667\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7586 - accuracy: 0.6667\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7575 - accuracy: 0.6667\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7564 - accuracy: 0.6667\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7553 - accuracy: 0.6667\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7541 - accuracy: 0.6667\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7529 - accuracy: 0.6667\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7517 - accuracy: 0.6667\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7504 - accuracy: 0.6667\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7492 - accuracy: 0.6667\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7479 - accuracy: 0.6667\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7465 - accuracy: 0.6667\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7451 - accuracy: 0.6667\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7437 - accuracy: 0.6667\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7423 - accuracy: 0.8333\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7408 - accuracy: 0.8333\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7393 - accuracy: 0.8333\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7377 - accuracy: 0.8333\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.7361 - accuracy: 0.8333\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7345 - accuracy: 0.8333\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7329 - accuracy: 0.8333\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7311 - accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7294 - accuracy: 0.8333\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.7276 - accuracy: 0.8333\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.7258 - accuracy: 0.8333\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7239 - accuracy: 0.8333\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7220 - accuracy: 0.8333\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7200 - accuracy: 0.8333\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7180 - accuracy: 0.8333\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7160 - accuracy: 0.8333\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7139 - accuracy: 0.8333\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.7117 - accuracy: 0.8333\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7095 - accuracy: 0.8333\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7073 - accuracy: 0.8333\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.7050 - accuracy: 0.8333\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.7027 - accuracy: 0.8333\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.7003 - accuracy: 0.8333\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6978 - accuracy: 0.8333\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6953 - accuracy: 0.8333\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6928 - accuracy: 0.8333\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6902 - accuracy: 0.8333\n",
      "Epoch 84/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6875 - accuracy: 0.8333\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6848 - accuracy: 0.8333\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6820 - accuracy: 0.8333\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6792 - accuracy: 0.8333\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6763 - accuracy: 0.8333\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6734 - accuracy: 0.8333\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6704 - accuracy: 0.8333\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6673 - accuracy: 0.8333\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6642 - accuracy: 0.8333\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6610 - accuracy: 0.8333\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6578 - accuracy: 0.8333\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6545 - accuracy: 0.8333\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6511 - accuracy: 0.8333\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6477 - accuracy: 0.8333\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6442 - accuracy: 0.8333\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6406 - accuracy: 0.8333\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6370 - accuracy: 0.8333\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6334 - accuracy: 0.8333\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6296 - accuracy: 0.8333\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.6258 - accuracy: 0.8333\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6220 - accuracy: 0.8333\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.6180 - accuracy: 0.8333\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.6140 - accuracy: 0.8333\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6100 - accuracy: 0.8333\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.6059 - accuracy: 0.8333\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.6017 - accuracy: 0.8333\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5974 - accuracy: 0.8333\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5931 - accuracy: 0.8333\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5888 - accuracy: 0.8333\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5843 - accuracy: 0.8333\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.5798 - accuracy: 0.8333\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5752 - accuracy: 0.8333\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5706 - accuracy: 0.8333\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5659 - accuracy: 0.8333\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.5612 - accuracy: 0.8333\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.5563 - accuracy: 0.8333\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.5514 - accuracy: 0.8333\n",
      "Epoch 121/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.5465 - accuracy: 0.8333\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.5415 - accuracy: 0.8333\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.5364 - accuracy: 0.8333\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 1.5313 - accuracy: 0.8333\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 1.5261 - accuracy: 0.8333\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 1.5209 - accuracy: 0.8333\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 1.5155 - accuracy: 0.8333\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5102 - accuracy: 0.8333\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.5048 - accuracy: 0.8333\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4993 - accuracy: 0.8333\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4937 - accuracy: 0.8333\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 1.4881 - accuracy: 0.8333\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4825 - accuracy: 0.8333\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4768 - accuracy: 0.8333\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.4710 - accuracy: 0.8333\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4652 - accuracy: 0.8333\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4594 - accuracy: 0.8333\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4534 - accuracy: 0.8333\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.4475 - accuracy: 0.8333\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4415 - accuracy: 0.8333\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.4354 - accuracy: 0.8333\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4293 - accuracy: 0.8333\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4232 - accuracy: 0.8333\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.4170 - accuracy: 0.8333\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.4107 - accuracy: 0.8333\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.4044 - accuracy: 0.8333\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3981 - accuracy: 0.8333\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3917 - accuracy: 0.8333\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3853 - accuracy: 0.8333\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3789 - accuracy: 0.8333\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.3724 - accuracy: 0.8333\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3659 - accuracy: 0.8333\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3593 - accuracy: 0.8333\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3527 - accuracy: 0.8333\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3461 - accuracy: 0.8333\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3395 - accuracy: 0.8333\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.3328 - accuracy: 0.8333\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3261 - accuracy: 0.8333\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.3193 - accuracy: 0.8333\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.3126 - accuracy: 0.8333\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.3058 - accuracy: 0.8333\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2990 - accuracy: 0.8333\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2921 - accuracy: 0.8333\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.2853 - accuracy: 0.8333\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2784 - accuracy: 0.8333\n",
      "Epoch 166/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2715 - accuracy: 0.8333\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2646 - accuracy: 0.8333\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2576 - accuracy: 0.8333\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.2507 - accuracy: 0.8333\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.2437 - accuracy: 0.8333\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.2367 - accuracy: 0.8333\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2297 - accuracy: 0.8333\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.2227 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2157 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.2087 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 1.2016 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1946 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 1.1875 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 1.1805 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 1.1734 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1664 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 1.1593 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1522 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.1452 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.1381 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.1310 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1240 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1169 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.1099 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.1028 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0958 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0888 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0818 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0748 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0678 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 1.0608 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0538 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.0469 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.0399 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 1.0330 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "train = model.fit(x_train,y_train,epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1f1b6e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1b32ed18d30>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting model accuracy\n",
    "plt.plot(train.history['accuracy'],label='training set accuracy')\n",
    "plt.plot(train.history['loss'],label='training set loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c9f617fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving model\n",
    "import os.path\n",
    "if os.path.isfile(\"Predictplan001\") is False:\n",
    "    model.save(\"Predictplan001.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dc3143f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4224623672.py, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [83]\u001b[1;36m\u001b[0m\n\u001b[1;33m    if prediction_input == \"End\"\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Testing Model\n",
    "# chatting\n",
    "import random\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "#Loading model\n",
    "reconstructed_model = keras.models.load_model(\"Predictplan001.h5\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    texts_p = []\n",
    "    prediction_input = input('You : ')\n",
    "\n",
    "    #removing punctuation and converting to lowercase\n",
    "    prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
    "    prediction_input = ''.join(prediction_input)\n",
    "    texts_p.append(prediction_input)\n",
    "    \n",
    "    #tokenizing and padding\n",
    "    prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
    "    prediction_input = np.array(prediction_input).reshape(-1)\n",
    "    prediction_input = pad_sequences([prediction_input],input_shape)\n",
    "    \n",
    "    \n",
    "    #getting output from model\n",
    "    output = reconstructed_model.predict(prediction_input)\n",
    "    output = output.argmax()\n",
    "    \n",
    "    #finding the right tag and predicting\n",
    "    response_tag = le.inverse_transform([output])[0]\n",
    "    print(\"Output :\",random.choice(responses[response_tag]))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
